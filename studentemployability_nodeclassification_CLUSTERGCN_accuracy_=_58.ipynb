{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cncu-nl9lfoV",
        "outputId": "2d683a09-e5a9-4b0a-eaf6-048328294cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stellargraph in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (3.2.2)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (2.9.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (2.3)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (1.3.5)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.8/dist-packages (from stellargraph) (1.0.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.4.0->stellargraph) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.4.0->stellargraph) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->stellargraph) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->stellargraph) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->stellargraph) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->stellargraph) (0.11.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.2->stellargraph) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24->stellargraph) (2022.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->stellargraph) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->stellargraph) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.12)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.9.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.51.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (15.0.6.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (4.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (21.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.29.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->stellargraph) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (2.25.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (5.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->stellargraph) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stellargraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx==2.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXohTyuW0S3L",
        "outputId": "03a7d4a6-ac1b-4a75-fc51-e14690e03036"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx==2.3 in /usr/local/lib/python3.8/dist-packages (2.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from networkx==2.3) (4.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all necessary libraries\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import os\n",
        "import networkx as nx\n",
        "import stellargraph as sg\n",
        "from stellargraph import StellarGraph\n",
        "from sklearn import preprocessing, model_selection\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "#from node2vec import Node2Vec as n2v\n",
        "sns.set()\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "gR5IuYl2ljDG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Student-Employability-Dataset.csv')\n",
        "df.head()\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "nOzycvYGljGI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c681ff3a-00f3-499a-ad63-ab0977e15c9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   GENERAL APPEARANCE  MANNER OF SPEAKING  PHYSICAL CONDITION  \\\n",
              "0                   4                   5                   4   \n",
              "1                   4                   4                   4   \n",
              "2                   4                   3                   3   \n",
              "3                   3                   3                   3   \n",
              "4                   4                   4                   3   \n",
              "\n",
              "   MENTAL ALERTNESS  SELF-CONFIDENCE  ABILITY TO PRESENT IDEAS  \\\n",
              "0                 5                5                         5   \n",
              "1                 4                4                         4   \n",
              "2                 3                3                         3   \n",
              "3                 2                3                         3   \n",
              "4                 3                4                         4   \n",
              "\n",
              "   COMMUNICATION SKILLS  Student Performance Rating           CLASS  \n",
              "0                     5                           5      Employable  \n",
              "1                     3                           5      Employable  \n",
              "2                     2                           5  LessEmployable  \n",
              "3                     3                           5  LessEmployable  \n",
              "4                     3                           5      Employable  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0955a24a-31ac-49b9-acef-890ec2b175a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENERAL APPEARANCE</th>\n",
              "      <th>MANNER OF SPEAKING</th>\n",
              "      <th>PHYSICAL CONDITION</th>\n",
              "      <th>MENTAL ALERTNESS</th>\n",
              "      <th>SELF-CONFIDENCE</th>\n",
              "      <th>ABILITY TO PRESENT IDEAS</th>\n",
              "      <th>COMMUNICATION SKILLS</th>\n",
              "      <th>Student Performance Rating</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Employable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>Employable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>LessEmployable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>LessEmployable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>Employable</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0955a24a-31ac-49b9-acef-890ec2b175a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0955a24a-31ac-49b9-acef-890ec2b175a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0955a24a-31ac-49b9-acef-890ec2b175a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWhNFwemmeQ7",
        "outputId": "35c84462-1f2c-4cbc-d922-7f3a0309e19e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2982, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['CLASS'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Ce8z5lnxAu",
        "outputId": "db39445c-249f-4282-e1b7-e71ccbcf546d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Employable        1729\n",
              "LessEmployable    1253\n",
              "Name: CLASS, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = {'Employable' : 1, 'LessEmployable' : 0}\n",
        "df['CLASS'] = df['CLASS'].map(z)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zecQWODIjag1",
        "outputId": "be19fccb-0cdc-4bde-81e2-e49dd6115375"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   GENERAL APPEARANCE  MANNER OF SPEAKING  PHYSICAL CONDITION  \\\n",
              "0                   4                   5                   4   \n",
              "1                   4                   4                   4   \n",
              "2                   4                   3                   3   \n",
              "3                   3                   3                   3   \n",
              "4                   4                   4                   3   \n",
              "\n",
              "   MENTAL ALERTNESS  SELF-CONFIDENCE  ABILITY TO PRESENT IDEAS  \\\n",
              "0                 5                5                         5   \n",
              "1                 4                4                         4   \n",
              "2                 3                3                         3   \n",
              "3                 2                3                         3   \n",
              "4                 3                4                         4   \n",
              "\n",
              "   COMMUNICATION SKILLS  Student Performance Rating  CLASS  \n",
              "0                     5                           5      1  \n",
              "1                     3                           5      1  \n",
              "2                     2                           5      0  \n",
              "3                     3                           5      0  \n",
              "4                     3                           5      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-623eddde-72f4-4946-a150-0fda6ccbb067\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENERAL APPEARANCE</th>\n",
              "      <th>MANNER OF SPEAKING</th>\n",
              "      <th>PHYSICAL CONDITION</th>\n",
              "      <th>MENTAL ALERTNESS</th>\n",
              "      <th>SELF-CONFIDENCE</th>\n",
              "      <th>ABILITY TO PRESENT IDEAS</th>\n",
              "      <th>COMMUNICATION SKILLS</th>\n",
              "      <th>Student Performance Rating</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-623eddde-72f4-4946-a150-0fda6ccbb067')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-623eddde-72f4-4946-a150-0fda6ccbb067 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-623eddde-72f4-4946-a150-0fda6ccbb067');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#node_Class\n",
        "node_Class = df[\"CLASS\"]"
      ],
      "metadata": {
        "id": "tlYy11i7meUP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u3=df.drop(['CLASS'], axis=1)\n",
        "u3.head()"
      ],
      "metadata": {
        "id": "ec_H82x-n5lO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "183710f9-3e03-4c37-9aa3-ba059fbf57f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   GENERAL APPEARANCE  MANNER OF SPEAKING  PHYSICAL CONDITION  \\\n",
              "0                   4                   5                   4   \n",
              "1                   4                   4                   4   \n",
              "2                   4                   3                   3   \n",
              "3                   3                   3                   3   \n",
              "4                   4                   4                   3   \n",
              "\n",
              "   MENTAL ALERTNESS  SELF-CONFIDENCE  ABILITY TO PRESENT IDEAS  \\\n",
              "0                 5                5                         5   \n",
              "1                 4                4                         4   \n",
              "2                 3                3                         3   \n",
              "3                 2                3                         3   \n",
              "4                 3                4                         4   \n",
              "\n",
              "   COMMUNICATION SKILLS  Student Performance Rating  \n",
              "0                     5                           5  \n",
              "1                     3                           5  \n",
              "2                     2                           5  \n",
              "3                     3                           5  \n",
              "4                     3                           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ba22bc8-4be3-4bf9-8aec-6ebc1374ce10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENERAL APPEARANCE</th>\n",
              "      <th>MANNER OF SPEAKING</th>\n",
              "      <th>PHYSICAL CONDITION</th>\n",
              "      <th>MENTAL ALERTNESS</th>\n",
              "      <th>SELF-CONFIDENCE</th>\n",
              "      <th>ABILITY TO PRESENT IDEAS</th>\n",
              "      <th>COMMUNICATION SKILLS</th>\n",
              "      <th>Student Performance Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ba22bc8-4be3-4bf9-8aec-6ebc1374ce10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ba22bc8-4be3-4bf9-8aec-6ebc1374ce10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ba22bc8-4be3-4bf9-8aec-6ebc1374ce10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance calculation for creating adjacency matrix\n"
      ],
      "metadata": {
        "id": "ZLv7lbrF4lo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "s = cdist(u3, u3, 'cosine')\n",
        "s"
      ],
      "metadata": {
        "id": "ykcfyEHVtr1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25744f5d-827b-444b-8e1d-ee1d0620e5f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00000000e+00, 1.18196406e-02, 3.89451766e-02, ...,\n",
              "        5.70574961e-03, 1.75078592e-02, 1.18196406e-02],\n",
              "       [1.18196406e-02, 0.00000000e+00, 1.07846501e-02, ...,\n",
              "        6.69736532e-03, 3.57110435e-03, 7.69230769e-03],\n",
              "       [3.89451766e-02, 1.07846501e-02, 0.00000000e+00, ...,\n",
              "        2.63323597e-02, 1.15390226e-02, 2.00296533e-02],\n",
              "       ...,\n",
              "       [5.70574961e-03, 6.69736532e-03, 2.63323597e-02, ...,\n",
              "        0.00000000e+00, 1.50356688e-02, 6.69736532e-03],\n",
              "       [1.75078592e-02, 3.57110435e-03, 1.15390226e-02, ...,\n",
              "        1.50356688e-02, 1.11022302e-16, 1.14792702e-02],\n",
              "       [1.18196406e-02, 7.69230769e-03, 2.00296533e-02, ...,\n",
              "        6.69736532e-03, 1.14792702e-02, 0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1=pd.DataFrame(s)\n",
        "X1"
      ],
      "metadata": {
        "id": "iJ61mEGstr5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "6a302c79-73ee-458b-a9cf-ee8a64cbff35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6     \\\n",
              "0     0.000000  0.011820  0.038945  0.031784  0.015827  0.023852  0.023828   \n",
              "1     0.011820  0.000000  0.010785  0.018050  0.006520  0.010005  0.017776   \n",
              "2     0.038945  0.010785  0.000000  0.016536  0.011513  0.008478  0.038122   \n",
              "3     0.031784  0.018050  0.016536  0.000000  0.011438  0.010986  0.043910   \n",
              "4     0.015827  0.006520  0.011513  0.011438  0.000000  0.007125  0.027587   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2977  0.038945  0.010785  0.000000  0.016536  0.011513  0.008478  0.038122   \n",
              "2978  0.005318  0.007692  0.029275  0.018050  0.014663  0.018689  0.026871   \n",
              "2979  0.005706  0.006697  0.026332  0.030187  0.015583  0.013821  0.017178   \n",
              "2980  0.017508  0.003571  0.011539  0.010289  0.003757  0.009008  0.018263   \n",
              "2981  0.011820  0.007692  0.020030  0.018050  0.014663  0.010005  0.017776   \n",
              "\n",
              "          7         8         9     ...      2972      2973      2974  \\\n",
              "0     0.036119  0.005732  0.010824  ...  0.055234  0.021551  0.015827   \n",
              "1     0.017689  0.003403  0.011479  ...  0.039031  0.008924  0.006520   \n",
              "2     0.009505  0.018376  0.021043  ...  0.021836  0.019694  0.011513   \n",
              "3     0.031092  0.015332  0.020186  ...  0.030511  0.023098  0.021630   \n",
              "4     0.021789  0.008436  0.012128  ...  0.034596  0.015815  0.008621   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2977  0.009505  0.018376  0.021043  ...  0.021836  0.019694  0.011513   \n",
              "2978  0.034339  0.003403  0.011479  ...  0.048837  0.017695  0.014663   \n",
              "2979  0.024151  0.004957  0.007793  ...  0.039112  0.020072  0.008125   \n",
              "2980  0.024357  0.006251  0.016260  ...  0.042308  0.008163  0.012128   \n",
              "2981  0.017689  0.003403  0.003571  ...  0.029225  0.017695  0.006520   \n",
              "\n",
              "          2975      2976      2977      2978      2979          2980      2981  \n",
              "0     0.022710  0.031191  0.038945  0.005318  0.005706  1.750786e-02  0.011820  \n",
              "1     0.006520  0.018689  0.010785  0.007692  0.006697  3.571104e-03  0.007692  \n",
              "2     0.011513  0.018915  0.000000  0.029275  0.026332  1.153902e-02  0.020030  \n",
              "3     0.021630  0.043591  0.016536  0.018050  0.030187  1.028900e-02  0.018050  \n",
              "4     0.017241  0.025511  0.011513  0.014663  0.015583  3.756706e-03  0.014663  \n",
              "...        ...       ...       ...       ...       ...           ...       ...  \n",
              "2977  0.011513  0.018915  0.000000  0.029275  0.026332  1.153902e-02  0.020030  \n",
              "2978  0.014663  0.036057  0.029275  0.000000  0.006697  1.147927e-02  0.007692  \n",
              "2979  0.008125  0.021774  0.026332  0.006697  0.000000  1.503567e-02  0.006697  \n",
              "2980  0.012128  0.026863  0.011539  0.011479  0.015036  1.110223e-16  0.011479  \n",
              "2981  0.006520  0.018689  0.020030  0.007692  0.006697  1.147927e-02  0.000000  \n",
              "\n",
              "[2982 rows x 2982 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9633841-09b3-4db1-9cec-82b733c16585\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011820</td>\n",
              "      <td>0.038945</td>\n",
              "      <td>0.031784</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.023852</td>\n",
              "      <td>0.023828</td>\n",
              "      <td>0.036119</td>\n",
              "      <td>0.005732</td>\n",
              "      <td>0.010824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055234</td>\n",
              "      <td>0.021551</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.022710</td>\n",
              "      <td>0.031191</td>\n",
              "      <td>0.038945</td>\n",
              "      <td>0.005318</td>\n",
              "      <td>0.005706</td>\n",
              "      <td>1.750786e-02</td>\n",
              "      <td>0.011820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.011820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.006520</td>\n",
              "      <td>0.010005</td>\n",
              "      <td>0.017776</td>\n",
              "      <td>0.017689</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>0.011479</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039031</td>\n",
              "      <td>0.008924</td>\n",
              "      <td>0.006520</td>\n",
              "      <td>0.006520</td>\n",
              "      <td>0.018689</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>3.571104e-03</td>\n",
              "      <td>0.007692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.038945</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016536</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.008478</td>\n",
              "      <td>0.038122</td>\n",
              "      <td>0.009505</td>\n",
              "      <td>0.018376</td>\n",
              "      <td>0.021043</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021836</td>\n",
              "      <td>0.019694</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.018915</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029275</td>\n",
              "      <td>0.026332</td>\n",
              "      <td>1.153902e-02</td>\n",
              "      <td>0.020030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.031784</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.016536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011438</td>\n",
              "      <td>0.010986</td>\n",
              "      <td>0.043910</td>\n",
              "      <td>0.031092</td>\n",
              "      <td>0.015332</td>\n",
              "      <td>0.020186</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030511</td>\n",
              "      <td>0.023098</td>\n",
              "      <td>0.021630</td>\n",
              "      <td>0.021630</td>\n",
              "      <td>0.043591</td>\n",
              "      <td>0.016536</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.030187</td>\n",
              "      <td>1.028900e-02</td>\n",
              "      <td>0.018050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.006520</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.011438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007125</td>\n",
              "      <td>0.027587</td>\n",
              "      <td>0.021789</td>\n",
              "      <td>0.008436</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034596</td>\n",
              "      <td>0.015815</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.025511</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.015583</td>\n",
              "      <td>3.756706e-03</td>\n",
              "      <td>0.014663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2977</th>\n",
              "      <td>0.038945</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016536</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.008478</td>\n",
              "      <td>0.038122</td>\n",
              "      <td>0.009505</td>\n",
              "      <td>0.018376</td>\n",
              "      <td>0.021043</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021836</td>\n",
              "      <td>0.019694</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>0.018915</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029275</td>\n",
              "      <td>0.026332</td>\n",
              "      <td>1.153902e-02</td>\n",
              "      <td>0.020030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2978</th>\n",
              "      <td>0.005318</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.029275</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.018689</td>\n",
              "      <td>0.026871</td>\n",
              "      <td>0.034339</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>0.011479</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048837</td>\n",
              "      <td>0.017695</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.036057</td>\n",
              "      <td>0.029275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>1.147927e-02</td>\n",
              "      <td>0.007692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2979</th>\n",
              "      <td>0.005706</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>0.026332</td>\n",
              "      <td>0.030187</td>\n",
              "      <td>0.015583</td>\n",
              "      <td>0.013821</td>\n",
              "      <td>0.017178</td>\n",
              "      <td>0.024151</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.007793</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039112</td>\n",
              "      <td>0.020072</td>\n",
              "      <td>0.008125</td>\n",
              "      <td>0.008125</td>\n",
              "      <td>0.021774</td>\n",
              "      <td>0.026332</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.503567e-02</td>\n",
              "      <td>0.006697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2980</th>\n",
              "      <td>0.017508</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.011539</td>\n",
              "      <td>0.010289</td>\n",
              "      <td>0.003757</td>\n",
              "      <td>0.009008</td>\n",
              "      <td>0.018263</td>\n",
              "      <td>0.024357</td>\n",
              "      <td>0.006251</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042308</td>\n",
              "      <td>0.008163</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.026863</td>\n",
              "      <td>0.011539</td>\n",
              "      <td>0.011479</td>\n",
              "      <td>0.015036</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>0.011479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2981</th>\n",
              "      <td>0.011820</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.020030</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.010005</td>\n",
              "      <td>0.017776</td>\n",
              "      <td>0.017689</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029225</td>\n",
              "      <td>0.017695</td>\n",
              "      <td>0.006520</td>\n",
              "      <td>0.006520</td>\n",
              "      <td>0.018689</td>\n",
              "      <td>0.020030</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>1.147927e-02</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2982 rows × 2982 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9633841-09b3-4db1-9cec-82b733c16585')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9633841-09b3-4db1-9cec-82b733c16585 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9633841-09b3-4db1-9cec-82b733c16585');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking average of the hamming distance matrix\n",
        "y = np.average(X1)\n",
        "y"
      ],
      "metadata": {
        "id": "UQs3yiDPlop3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8371c93-7e04-4c31-c85d-589bd95b32ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01856620671593297"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjmat_df=X1.copy()"
      ],
      "metadata": {
        "id": "o2zLWcNflosv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting threshold value as mean of hamming matrix\n",
        "adjmat_df[adjmat_df < y]=0\n",
        "adjmat_df[adjmat_df >= y]=1"
      ],
      "metadata": {
        "id": "ctydp1FtloyL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjacency matrix\n",
        "adjmat_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "96zM2mImivyQ",
        "outputId": "70ad79d2-3114-4f5d-9b8e-4f42a8f96485"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0     1     2     3     4     5     6     7     8     9     ...  2972  \\\n",
              "0      0.0   0.0   1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0  ...   1.0   \n",
              "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   1.0   \n",
              "2      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0  ...   1.0   \n",
              "3      1.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   1.0  ...   1.0   \n",
              "4      0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   1.0   \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "2977   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0  ...   1.0   \n",
              "2978   0.0   0.0   1.0   0.0   0.0   1.0   1.0   1.0   0.0   0.0  ...   1.0   \n",
              "2979   0.0   0.0   1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   1.0   \n",
              "2980   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   1.0   \n",
              "2981   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   1.0   \n",
              "\n",
              "      2973  2974  2975  2976  2977  2978  2979  2980  2981  \n",
              "0      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0  \n",
              "1      0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2      1.0   0.0   0.0   1.0   0.0   1.0   1.0   0.0   1.0  \n",
              "3      1.0   1.0   1.0   1.0   0.0   0.0   1.0   0.0   0.0  \n",
              "4      0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "2977   1.0   0.0   0.0   1.0   0.0   1.0   1.0   0.0   1.0  \n",
              "2978   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0  \n",
              "2979   1.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0  \n",
              "2980   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2981   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[2982 rows x 2982 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c62d6823-ae92-44b9-905c-cec45b90f5bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2977</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2978</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2979</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2980</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2981</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2982 rows × 2982 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c62d6823-ae92-44b9-905c-cec45b90f5bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c62d6823-ae92-44b9-905c-cec45b90f5bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c62d6823-ae92-44b9-905c-cec45b90f5bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.from_numpy_matrix(np.array(adjmat_df))\n",
        "G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTd5fl42ivz8",
        "outputId": "e6ddee6e-a6d4-483f-94fd-810e73282255"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7f68c481e790>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=nx.to_numpy_matrix(G)\n",
        "##Creating graph from adjacency matrix\n",
        "H=nx.from_numpy_matrix(A)"
      ],
      "metadata": {
        "id": "vm_vIlpNiv4S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct a graph using stellargraph"
      ],
      "metadata": {
        "id": "qIxeFMjSi6KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "square_feature_dataframe = StellarGraph.from_networkx(H, node_features=adjmat_df)\n",
        "print(square_feature_dataframe.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiD0zna5tFfp",
        "outputId": "076e63b2-8323-4e19-c80c-0a26595ab159"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 2982, Edges: 1793526\n",
            "\n",
            " Node types:\n",
            "  default: [2982]\n",
            "    Features: float32 vector, length 2982\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [1793526]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stellargraph.mapper import (\n",
        "    CorruptedGenerator,\n",
        "    FullBatchNodeGenerator,\n",
        "    GraphSAGENodeGenerator,\n",
        "    HinSAGENodeGenerator,\n",
        "    ClusterNodeGenerator,\n",
        ")\n",
        "from stellargraph import StellarGraph\n",
        "from stellargraph.layer import GCN, DeepGraphInfomax, GraphSAGE, GAT, APPNP, HinSAGE\n",
        "from stellargraph.mapper import ClusterNodeGenerator\n",
        "from stellargraph import datasets\n",
        "from stellargraph.utils import plot_history\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.manifold import TSNE\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "zFYxEqBOl_i5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Generator"
      ],
      "metadata": {
        "id": "v53x4L-czdMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_clusters = 10  # the number of clusters/subgraphs\n",
        "clusters_per_batch = 2  # combine two cluster per batch\n",
        "random_clusters = True  # Set to False if you want to use METIS for clustering"
      ],
      "metadata": {
        "id": "d_LprBFBzgW0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = ClusterNodeGenerator(square_feature_dataframe, clusters=number_of_clusters, q=clusters_per_batch, lam=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCoCgvF4bk3T",
        "outputId": "3e8c21f7-b68b-43eb-c29f-339aa4dcc16b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of clusters 10\n",
            "0 cluster has size 298\n",
            "1 cluster has size 298\n",
            "2 cluster has size 298\n",
            "3 cluster has size 298\n",
            "4 cluster has size 298\n",
            "5 cluster has size 298\n",
            "6 cluster has size 298\n",
            "7 cluster has size 298\n",
            "8 cluster has size 298\n",
            "9 cluster has size 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_gcn = GCN(\n",
        "    layer_sizes=[32, 32], activations=[\"relu\", \"relu\"], generator=generator, dropout=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "yyLUOC5DvPzN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_inp, x_out = cluster_gcn.in_out_tensors()"
      ],
      "metadata": {
        "id": "6zDtLredmTF7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_inp"
      ],
      "metadata": {
        "id": "unARj_UuZXfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85a7acb-774c-4b0c-8fd0-2e50648d33b3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(1, None, 2982) dtype=float32 (created by layer 'input_1')>,\n",
              " <KerasTensor: shape=(1, None) dtype=int32 (created by layer 'input_2')>,\n",
              " <KerasTensor: shape=(1, None, None) dtype=float32 (created by layer 'input_3')>]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig818jdUhCtc",
        "outputId": "f6ec2acc-d461-49d7-bfe7-e80147d13c26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(1, None, 32) dtype=float32 (created by layer 'gather_indices')>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_nodes = list(square_feature_dataframe.nodes())\n",
        "all_nodes "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHFRo5AlzuPL",
        "outputId": "f6c9113e-7af2-4ddd-b41b-802994858d17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_gen = generator.flow(all_nodes, name=\"all_gen\")\n",
        "all_gen "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C7vlocKzxXr",
        "outputId": "e1d01f6c-0ca2-46db-86cd-47f84f942c6b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stellargraph.mapper.mini_batch_node_generators.ClusterNodeSequence at 0x7f687bf41820>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
        "x_out_flat = layers.Lambda(lambda x: K.squeeze(x, 0))(x_out)\n",
        "x_out_flat\n",
        "embedding_model = Model(inputs=x_inp, outputs=x_out_flat)"
      ],
      "metadata": {
        "id": "QskkrWasz1C7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = Model(inputs=x_inp, outputs=x_out_flat)\n",
        "embedding_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JFydLPwz4YM",
        "outputId": "d67f4102-1f60-4fde-ed3b-dd908c452e72"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f687bf565e0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Embeddings"
      ],
      "metadata": {
        "id": "2tFe9739z_2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb = embedding_model.predict(all_gen, verbose=1)\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOVehdMZACZt",
        "outputId": "eac4f3dd-8915-4aa4-9dc4-a4f10a5db0e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 121ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2982, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUazaJ2vAJQT",
        "outputId": "121b8325-1b5d-4cbe-b3ae-5da1f49e860c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8924582 , 0.        , 0.        , ..., 0.        , 0.27458277,\n",
              "        0.        ],\n",
              "       [1.1752179 , 0.        , 0.        , ..., 0.        , 0.21696302,\n",
              "        0.        ],\n",
              "       [1.185036  , 0.        , 0.        , ..., 0.        , 0.2162255 ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [1.1268325 , 0.        , 0.        , ..., 0.        , 0.21875134,\n",
              "        0.        ],\n",
              "       [1.1049886 , 0.        , 0.        , ..., 0.        , 0.22968936,\n",
              "        0.        ],\n",
              "       [1.038402  , 0.        , 0.        , ..., 0.        , 0.22725907,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_emb = pd.DataFrame(emb)"
      ],
      "metadata": {
        "id": "tmQzLVunAMJL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=all_gen.node_order\n",
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ma23Zhe0H-s",
        "outputId": "d917ed15-efcc-4609-8fd6-f3bf88429a69"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2051,\n",
              " 2052,\n",
              " 7,\n",
              " 2055,\n",
              " 2058,\n",
              " 13,\n",
              " 14,\n",
              " 2062,\n",
              " 17,\n",
              " 2068,\n",
              " 24,\n",
              " 25,\n",
              " 2074,\n",
              " 34,\n",
              " 2084,\n",
              " 2085,\n",
              " 38,\n",
              " 45,\n",
              " 47,\n",
              " 50,\n",
              " 56,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 66,\n",
              " 2115,\n",
              " 2119,\n",
              " 2121,\n",
              " 76,\n",
              " 77,\n",
              " 2125,\n",
              " 2131,\n",
              " 86,\n",
              " 87,\n",
              " 2137,\n",
              " 2139,\n",
              " 93,\n",
              " 2142,\n",
              " 95,\n",
              " 2143,\n",
              " 98,\n",
              " 103,\n",
              " 104,\n",
              " 2152,\n",
              " 2153,\n",
              " 2154,\n",
              " 2156,\n",
              " 110,\n",
              " 112,\n",
              " 113,\n",
              " 115,\n",
              " 2166,\n",
              " 121,\n",
              " 2171,\n",
              " 126,\n",
              " 127,\n",
              " 132,\n",
              " 2185,\n",
              " 2189,\n",
              " 147,\n",
              " 2199,\n",
              " 2206,\n",
              " 159,\n",
              " 2209,\n",
              " 162,\n",
              " 163,\n",
              " 169,\n",
              " 170,\n",
              " 2219,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 187,\n",
              " 2239,\n",
              " 2242,\n",
              " 196,\n",
              " 202,\n",
              " 203,\n",
              " 2252,\n",
              " 205,\n",
              " 2258,\n",
              " 212,\n",
              " 216,\n",
              " 2265,\n",
              " 2267,\n",
              " 2270,\n",
              " 223,\n",
              " 225,\n",
              " 227,\n",
              " 228,\n",
              " 2277,\n",
              " 230,\n",
              " 231,\n",
              " 2279,\n",
              " 2280,\n",
              " 234,\n",
              " 2281,\n",
              " 236,\n",
              " 237,\n",
              " 2284,\n",
              " 239,\n",
              " 240,\n",
              " 242,\n",
              " 244,\n",
              " 2293,\n",
              " 250,\n",
              " 252,\n",
              " 2302,\n",
              " 255,\n",
              " 2309,\n",
              " 268,\n",
              " 2317,\n",
              " 2318,\n",
              " 274,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 285,\n",
              " 286,\n",
              " 2333,\n",
              " 289,\n",
              " 298,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 2352,\n",
              " 306,\n",
              " 2356,\n",
              " 2358,\n",
              " 2359,\n",
              " 2365,\n",
              " 318,\n",
              " 2374,\n",
              " 2375,\n",
              " 332,\n",
              " 338,\n",
              " 2388,\n",
              " 342,\n",
              " 2391,\n",
              " 345,\n",
              " 348,\n",
              " 2397,\n",
              " 354,\n",
              " 2403,\n",
              " 359,\n",
              " 2408,\n",
              " 2411,\n",
              " 2412,\n",
              " 2417,\n",
              " 2419,\n",
              " 372,\n",
              " 2424,\n",
              " 380,\n",
              " 381,\n",
              " 2429,\n",
              " 384,\n",
              " 385,\n",
              " 389,\n",
              " 2439,\n",
              " 392,\n",
              " 2441,\n",
              " 399,\n",
              " 402,\n",
              " 2450,\n",
              " 405,\n",
              " 2454,\n",
              " 409,\n",
              " 410,\n",
              " 2465,\n",
              " 2467,\n",
              " 426,\n",
              " 2475,\n",
              " 428,\n",
              " 430,\n",
              " 431,\n",
              " 2478,\n",
              " 437,\n",
              " 443,\n",
              " 2491,\n",
              " 448,\n",
              " 2496,\n",
              " 453,\n",
              " 2501,\n",
              " 455,\n",
              " 456,\n",
              " 2512,\n",
              " 466,\n",
              " 468,\n",
              " 2518,\n",
              " 471,\n",
              " 2524,\n",
              " 2526,\n",
              " 2527,\n",
              " 480,\n",
              " 484,\n",
              " 491,\n",
              " 2539,\n",
              " 2542,\n",
              " 2546,\n",
              " 2547,\n",
              " 503,\n",
              " 2552,\n",
              " 505,\n",
              " 2556,\n",
              " 510,\n",
              " 511,\n",
              " 2560,\n",
              " 514,\n",
              " 517,\n",
              " 518,\n",
              " 2566,\n",
              " 520,\n",
              " 2571,\n",
              " 2572,\n",
              " 2573,\n",
              " 2574,\n",
              " 2578,\n",
              " 531,\n",
              " 536,\n",
              " 538,\n",
              " 2586,\n",
              " 2588,\n",
              " 547,\n",
              " 551,\n",
              " 2600,\n",
              " 556,\n",
              " 2607,\n",
              " 560,\n",
              " 2608,\n",
              " 2615,\n",
              " 570,\n",
              " 571,\n",
              " 574,\n",
              " 575,\n",
              " 2623,\n",
              " 577,\n",
              " 2624,\n",
              " 580,\n",
              " 581,\n",
              " 2628,\n",
              " 2632,\n",
              " 2636,\n",
              " 2638,\n",
              " 591,\n",
              " 592,\n",
              " 2640,\n",
              " 2649,\n",
              " 2652,\n",
              " 605,\n",
              " 608,\n",
              " 2659,\n",
              " 612,\n",
              " 2660,\n",
              " 614,\n",
              " 2661,\n",
              " 2664,\n",
              " 624,\n",
              " 2673,\n",
              " 2674,\n",
              " 627,\n",
              " 2676,\n",
              " 630,\n",
              " 631,\n",
              " 634,\n",
              " 2685,\n",
              " 2689,\n",
              " 2690,\n",
              " 2694,\n",
              " 648,\n",
              " 2697,\n",
              " 652,\n",
              " 656,\n",
              " 659,\n",
              " 660,\n",
              " 2712,\n",
              " 666,\n",
              " 667,\n",
              " 2714,\n",
              " 671,\n",
              " 2720,\n",
              " 2722,\n",
              " 2724,\n",
              " 2727,\n",
              " 684,\n",
              " 2733,\n",
              " 2734,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 2740,\n",
              " 695,\n",
              " 2743,\n",
              " 699,\n",
              " 702,\n",
              " 2753,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 2759,\n",
              " 715,\n",
              " 2760,\n",
              " 717,\n",
              " 2766,\n",
              " 725,\n",
              " 2775,\n",
              " 731,\n",
              " 732,\n",
              " 2783,\n",
              " 2784,\n",
              " 737,\n",
              " 743,\n",
              " 2792,\n",
              " 2793,\n",
              " 749,\n",
              " 2797,\n",
              " 2801,\n",
              " 755,\n",
              " 761,\n",
              " 2810,\n",
              " 2816,\n",
              " 2817,\n",
              " 2820,\n",
              " 2822,\n",
              " 776,\n",
              " 2826,\n",
              " 781,\n",
              " 782,\n",
              " 784,\n",
              " 789,\n",
              " 792,\n",
              " 2840,\n",
              " 2841,\n",
              " 2842,\n",
              " 2845,\n",
              " 798,\n",
              " 800,\n",
              " 2853,\n",
              " 2856,\n",
              " 2858,\n",
              " 814,\n",
              " 2863,\n",
              " 2866,\n",
              " 819,\n",
              " 2874,\n",
              " 2876,\n",
              " 2878,\n",
              " 834,\n",
              " 2883,\n",
              " 2884,\n",
              " 838,\n",
              " 2890,\n",
              " 2894,\n",
              " 847,\n",
              " 852,\n",
              " 2901,\n",
              " 2902,\n",
              " 2904,\n",
              " 857,\n",
              " 859,\n",
              " 863,\n",
              " 2913,\n",
              " 2914,\n",
              " 872,\n",
              " 2921,\n",
              " 875,\n",
              " 2927,\n",
              " 884,\n",
              " 886,\n",
              " 887,\n",
              " 897,\n",
              " 899,\n",
              " 900,\n",
              " 2949,\n",
              " 902,\n",
              " 903,\n",
              " 2950,\n",
              " 2951,\n",
              " 2955,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 2959,\n",
              " 2962,\n",
              " 2967,\n",
              " 920,\n",
              " 2969,\n",
              " 925,\n",
              " 2974,\n",
              " 928,\n",
              " 2978,\n",
              " 2980,\n",
              " 939,\n",
              " 946,\n",
              " 948,\n",
              " 955,\n",
              " 971,\n",
              " 977,\n",
              " 978,\n",
              " 981,\n",
              " 990,\n",
              " 1006,\n",
              " 1008,\n",
              " 1012,\n",
              " 1014,\n",
              " 1016,\n",
              " 1021,\n",
              " 1022,\n",
              " 1029,\n",
              " 1030,\n",
              " 1033,\n",
              " 1036,\n",
              " 1037,\n",
              " 1042,\n",
              " 1044,\n",
              " 1045,\n",
              " 1047,\n",
              " 1048,\n",
              " 1053,\n",
              " 1056,\n",
              " 1068,\n",
              " 1075,\n",
              " 1090,\n",
              " 1092,\n",
              " 1096,\n",
              " 1105,\n",
              " 1108,\n",
              " 1111,\n",
              " 1114,\n",
              " 1116,\n",
              " 1120,\n",
              " 1127,\n",
              " 1128,\n",
              " 1129,\n",
              " 1135,\n",
              " 1137,\n",
              " 1140,\n",
              " 1146,\n",
              " 1150,\n",
              " 1151,\n",
              " 1161,\n",
              " 1163,\n",
              " 1177,\n",
              " 1180,\n",
              " 1184,\n",
              " 1187,\n",
              " 1189,\n",
              " 1198,\n",
              " 1209,\n",
              " 1210,\n",
              " 1212,\n",
              " 1214,\n",
              " 1219,\n",
              " 1224,\n",
              " 1226,\n",
              " 1228,\n",
              " 1232,\n",
              " 1233,\n",
              " 1247,\n",
              " 1249,\n",
              " 1253,\n",
              " 1255,\n",
              " 1256,\n",
              " 1265,\n",
              " 1269,\n",
              " 1292,\n",
              " 1296,\n",
              " 1297,\n",
              " 1302,\n",
              " 1307,\n",
              " 1311,\n",
              " 1316,\n",
              " 1320,\n",
              " 1338,\n",
              " 1344,\n",
              " 1345,\n",
              " 1358,\n",
              " 1359,\n",
              " 1361,\n",
              " 1369,\n",
              " 1373,\n",
              " 1386,\n",
              " 1388,\n",
              " 1389,\n",
              " 1390,\n",
              " 1403,\n",
              " 1409,\n",
              " 1412,\n",
              " 1428,\n",
              " 1431,\n",
              " 1435,\n",
              " 1441,\n",
              " 1452,\n",
              " 1461,\n",
              " 1467,\n",
              " 1469,\n",
              " 1470,\n",
              " 1471,\n",
              " 1484,\n",
              " 1493,\n",
              " 1499,\n",
              " 1506,\n",
              " 1507,\n",
              " 1526,\n",
              " 1533,\n",
              " 1541,\n",
              " 1557,\n",
              " 1563,\n",
              " 1568,\n",
              " 1570,\n",
              " 1576,\n",
              " 1585,\n",
              " 1590,\n",
              " 1594,\n",
              " 1595,\n",
              " 1605,\n",
              " 1606,\n",
              " 1611,\n",
              " 1621,\n",
              " 1636,\n",
              " 1637,\n",
              " 1639,\n",
              " 1650,\n",
              " 1667,\n",
              " 1668,\n",
              " 1670,\n",
              " 1673,\n",
              " 1675,\n",
              " 1678,\n",
              " 1689,\n",
              " 1697,\n",
              " 1702,\n",
              " 1709,\n",
              " 1713,\n",
              " 1714,\n",
              " 1715,\n",
              " 1721,\n",
              " 1736,\n",
              " 1738,\n",
              " 1739,\n",
              " 1741,\n",
              " 1745,\n",
              " 1752,\n",
              " 1753,\n",
              " 1762,\n",
              " 1764,\n",
              " 1765,\n",
              " 1770,\n",
              " 1771,\n",
              " 1788,\n",
              " 1789,\n",
              " 1800,\n",
              " 1801,\n",
              " 1807,\n",
              " 1808,\n",
              " 1811,\n",
              " 1816,\n",
              " 1823,\n",
              " 1826,\n",
              " 1839,\n",
              " 1841,\n",
              " 1845,\n",
              " 1856,\n",
              " 1862,\n",
              " 1864,\n",
              " 1870,\n",
              " 1875,\n",
              " 1878,\n",
              " 1879,\n",
              " 1885,\n",
              " 1896,\n",
              " 1900,\n",
              " 1907,\n",
              " 1910,\n",
              " 1919,\n",
              " 1922,\n",
              " 1924,\n",
              " 1927,\n",
              " 1945,\n",
              " 1953,\n",
              " 1954,\n",
              " 1957,\n",
              " 1958,\n",
              " 1964,\n",
              " 1967,\n",
              " 1975,\n",
              " 1980,\n",
              " 1983,\n",
              " 1985,\n",
              " 1998,\n",
              " 2009,\n",
              " 2010,\n",
              " 2016,\n",
              " 2020,\n",
              " 2037,\n",
              " 2039,\n",
              " 2042,\n",
              " 0,\n",
              " 2048,\n",
              " 2056,\n",
              " 2057,\n",
              " 10,\n",
              " 2059,\n",
              " 12,\n",
              " 20,\n",
              " 2069,\n",
              " 2070,\n",
              " 2073,\n",
              " 2076,\n",
              " 2077,\n",
              " 2079,\n",
              " 33,\n",
              " 36,\n",
              " 44,\n",
              " 52,\n",
              " 2100,\n",
              " 55,\n",
              " 2103,\n",
              " 2106,\n",
              " 2107,\n",
              " 60,\n",
              " 2111,\n",
              " 64,\n",
              " 2113,\n",
              " 2114,\n",
              " 69,\n",
              " 74,\n",
              " 75,\n",
              " 2124,\n",
              " 82,\n",
              " 2135,\n",
              " 89,\n",
              " 97,\n",
              " 2147,\n",
              " 101,\n",
              " 102,\n",
              " 2150,\n",
              " 105,\n",
              " 2155,\n",
              " 2157,\n",
              " 111,\n",
              " 2160,\n",
              " 114,\n",
              " 118,\n",
              " 119,\n",
              " 2167,\n",
              " 2169,\n",
              " 2170,\n",
              " 124,\n",
              " 2180,\n",
              " 134,\n",
              " 138,\n",
              " 139,\n",
              " 141,\n",
              " 2191,\n",
              " 2193,\n",
              " 146,\n",
              " 2194,\n",
              " 148,\n",
              " 2198,\n",
              " 151,\n",
              " 155,\n",
              " 156,\n",
              " 2204,\n",
              " 2207,\n",
              " 160,\n",
              " 166,\n",
              " 2217,\n",
              " 2218,\n",
              " 174,\n",
              " 175,\n",
              " 2223,\n",
              " 180,\n",
              " 2228,\n",
              " 182,\n",
              " 2229,\n",
              " 2232,\n",
              " 186,\n",
              " 2236,\n",
              " 189,\n",
              " 192,\n",
              " 194,\n",
              " 197,\n",
              " 2247,\n",
              " 2250,\n",
              " 204,\n",
              " 2256,\n",
              " 2259,\n",
              " 214,\n",
              " 2262,\n",
              " 2266,\n",
              " 219,\n",
              " 2271,\n",
              " 2275,\n",
              " 229,\n",
              " 235,\n",
              " 2288,\n",
              " 246,\n",
              " 2303,\n",
              " 259,\n",
              " 2307,\n",
              " 2308,\n",
              " 262,\n",
              " 264,\n",
              " 265,\n",
              " 2313,\n",
              " 2315,\n",
              " 2316,\n",
              " 2319,\n",
              " 272,\n",
              " 2320,\n",
              " 2321,\n",
              " 275,\n",
              " 2323,\n",
              " 280,\n",
              " 281,\n",
              " 283,\n",
              " 2331,\n",
              " 2336,\n",
              " 2337,\n",
              " 2346,\n",
              " 2348,\n",
              " 2351,\n",
              " 2353,\n",
              " 316,\n",
              " 2364,\n",
              " 2366,\n",
              " 319,\n",
              " 327,\n",
              " 2377,\n",
              " 330,\n",
              " 2379,\n",
              " 2382,\n",
              " 336,\n",
              " 2393,\n",
              " 346,\n",
              " 347,\n",
              " 2395,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 357,\n",
              " 2406,\n",
              " 364,\n",
              " 365,\n",
              " 2413,\n",
              " 2418,\n",
              " 373,\n",
              " 2421,\n",
              " 2422,\n",
              " 378,\n",
              " 2430,\n",
              " 386,\n",
              " 2437,\n",
              " 393,\n",
              " 394,\n",
              " 2442,\n",
              " 396,\n",
              " 2446,\n",
              " 2461,\n",
              " 2462,\n",
              " 419,\n",
              " 421,\n",
              " 2471,\n",
              " 424,\n",
              " 2472,\n",
              " 427,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 2489,\n",
              " 442,\n",
              " 446,\n",
              " 2498,\n",
              " 2500,\n",
              " 2502,\n",
              " 2503,\n",
              " 458,\n",
              " 2506,\n",
              " 460,\n",
              " 2508,\n",
              " 462,\n",
              " 2514,\n",
              " 2515,\n",
              " 2521,\n",
              " 475,\n",
              " 2523,\n",
              " 2525,\n",
              " 478,\n",
              " 2533,\n",
              " 2534,\n",
              " 490,\n",
              " 2540,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 2543,\n",
              " 2544,\n",
              " 2545,\n",
              " 500,\n",
              " 2548,\n",
              " 504,\n",
              " 509,\n",
              " 2557,\n",
              " 2561,\n",
              " 515,\n",
              " 2564,\n",
              " 2567,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 530,\n",
              " 2580,\n",
              " 2582,\n",
              " 535,\n",
              " 2584,\n",
              " 540,\n",
              " 2589,\n",
              " 545,\n",
              " 2603,\n",
              " 2605,\n",
              " 2609,\n",
              " 562,\n",
              " 563,\n",
              " 2611,\n",
              " 567,\n",
              " 569,\n",
              " 2618,\n",
              " 2619,\n",
              " 579,\n",
              " 582,\n",
              " 2630,\n",
              " 2633,\n",
              " 2635,\n",
              " 589,\n",
              " 2639,\n",
              " 2643,\n",
              " 2644,\n",
              " 601,\n",
              " 2651,\n",
              " 2653,\n",
              " 2656,\n",
              " 2658,\n",
              " 613,\n",
              " 621,\n",
              " 623,\n",
              " 626,\n",
              " 2678,\n",
              " 633,\n",
              " 637,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 651,\n",
              " 2701,\n",
              " 2702,\n",
              " 657,\n",
              " 661,\n",
              " 665,\n",
              " 2715,\n",
              " 668,\n",
              " 2716,\n",
              " 2717,\n",
              " 679,\n",
              " 2729,\n",
              " 682,\n",
              " 2731,\n",
              " 687,\n",
              " 692,\n",
              " 2742,\n",
              " 700,\n",
              " 2748,\n",
              " 704,\n",
              " 2752,\n",
              " 2756,\n",
              " 2762,\n",
              " 719,\n",
              " 2769,\n",
              " 723,\n",
              " 2776,\n",
              " 730,\n",
              " 733,\n",
              " 736,\n",
              " 738,\n",
              " 742,\n",
              " 2790,\n",
              " 2791,\n",
              " 745,\n",
              " 2794,\n",
              " 2795,\n",
              " 750,\n",
              " 752,\n",
              " 754,\n",
              " 756,\n",
              " 757,\n",
              " 2804,\n",
              " 759,\n",
              " 760,\n",
              " 2808,\n",
              " 762,\n",
              " 764,\n",
              " 2812,\n",
              " 766,\n",
              " 771,\n",
              " 772,\n",
              " 2821,\n",
              " 775,\n",
              " 779,\n",
              " 780,\n",
              " 2833,\n",
              " 787,\n",
              " 2835,\n",
              " 2837,\n",
              " 790,\n",
              " 795,\n",
              " 2843,\n",
              " 2849,\n",
              " 804,\n",
              " 2854,\n",
              " 2857,\n",
              " 811,\n",
              " 816,\n",
              " 818,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 827,\n",
              " 829,\n",
              " 830,\n",
              " 2882,\n",
              " 2889,\n",
              " 849,\n",
              " 855,\n",
              " 2906,\n",
              " 2909,\n",
              " 868,\n",
              " 869,\n",
              " 871,\n",
              " 2920,\n",
              " 2926,\n",
              " 881,\n",
              " 2933,\n",
              " 888,\n",
              " 2936,\n",
              " 2937,\n",
              " 891,\n",
              " 2939,\n",
              " 2941,\n",
              " 894,\n",
              " 2943,\n",
              " 2946,\n",
              " 904,\n",
              " 908,\n",
              " 915,\n",
              " 2963,\n",
              " 922,\n",
              " 2973,\n",
              " 926,\n",
              " 927,\n",
              " 2976,\n",
              " 932,\n",
              " 934,\n",
              " 938,\n",
              " 940,\n",
              " 942,\n",
              " 945,\n",
              " 949,\n",
              " 952,\n",
              " 956,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 969,\n",
              " 979,\n",
              " 985,\n",
              " 986,\n",
              " 989,\n",
              " 993,\n",
              " 995,\n",
              " 997,\n",
              " 998,\n",
              " 1001,\n",
              " 1007,\n",
              " 1010,\n",
              " 1013,\n",
              " 1018,\n",
              " 1027,\n",
              " 1039,\n",
              " 1052,\n",
              " 1054,\n",
              " 1065,\n",
              " 1066,\n",
              " 1069,\n",
              " 1070,\n",
              " 1080,\n",
              " 1081,\n",
              " 1082,\n",
              " 1086,\n",
              " 1093,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['CLASS'].reindex(index=all_gen.node_order)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkvPeWqq0KbE",
        "outputId": "f424651b-4fd3-4148-a01d-d3603fb4a17d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2051    0\n",
              "2052    1\n",
              "7       1\n",
              "2055    1\n",
              "2058    1\n",
              "       ..\n",
              "2022    0\n",
              "2026    1\n",
              "2027    1\n",
              "2038    0\n",
              "2045    1\n",
              "Name: CLASS, Length: 2982, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_emb['Class']=y"
      ],
      "metadata": {
        "id": "guDE3SEKAogq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EslfixqoAoiW",
        "outputId": "e87170dd-da40-4c9a-8962-e4d43a87d533"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0    1    2         3         4         5    6         7  \\\n",
              "0     0.892458  0.0  0.0  0.062522  0.044068  0.340021  0.0  0.132123   \n",
              "1     1.175218  0.0  0.0  0.190825  0.029893  0.364648  0.0  0.200019   \n",
              "2     1.185036  0.0  0.0  0.149677  0.000605  0.388964  0.0  0.223286   \n",
              "3     0.781864  0.0  0.0  0.000000  0.000000  0.371366  0.0  0.188209   \n",
              "4     0.894115  0.0  0.0  0.100781  0.045623  0.313692  0.0  0.118110   \n",
              "...        ...  ...  ...       ...       ...       ...  ...       ...   \n",
              "2977  1.075108  0.0  0.0  0.269159  0.109561  0.265193  0.0  0.063702   \n",
              "2978  0.851854  0.0  0.0  0.000000  0.000000  0.362215  0.0  0.169393   \n",
              "2979  1.126832  0.0  0.0  0.101847  0.000000  0.364256  0.0  0.232359   \n",
              "2980  1.104989  0.0  0.0  0.072007  0.000000  0.373690  0.0  0.234248   \n",
              "2981  1.038402  0.0  0.0  0.010663  0.000000  0.387717  0.0  0.233383   \n",
              "\n",
              "             8         9  ...        23        24   25        26        27  \\\n",
              "0     0.601586  0.693279  ...  0.125758  1.456933  0.0  0.010732  0.445896   \n",
              "1     0.692391  0.829105  ...  0.201026  1.800807  0.0  0.000000  0.615573   \n",
              "2     0.661359  0.860664  ...  0.236633  1.844458  0.0  0.000000  0.601454   \n",
              "3     0.534919  0.746612  ...  0.214941  1.454348  0.0  0.039566  0.374554   \n",
              "4     0.606111  0.661935  ...  0.072218  1.421055  0.0  0.007169  0.444806   \n",
              "...        ...       ...  ...       ...       ...  ...       ...       ...   \n",
              "2977  0.706344  0.710535  ...  0.142675  1.601235  0.0  0.032162  0.602430   \n",
              "2978  0.513054  0.748830  ...  0.183976  1.462657  0.0  0.018008  0.375786   \n",
              "2979  0.640165  0.856988  ...  0.272106  1.817077  0.0  0.000000  0.588062   \n",
              "2980  0.616639  0.866215  ...  0.249024  1.799792  0.0  0.000000  0.582558   \n",
              "2981  0.577342  0.853386  ...  0.268971  1.740742  0.0  0.000000  0.518036   \n",
              "\n",
              "       28   29        30   31  Class  \n",
              "0     0.0  0.0  0.274583  0.0      1  \n",
              "1     0.0  0.0  0.216963  0.0      1  \n",
              "2     0.0  0.0  0.216226  0.0      0  \n",
              "3     0.0  0.0  0.235217  0.0      0  \n",
              "4     0.0  0.0  0.309689  0.0      1  \n",
              "...   ...  ...       ...  ...    ...  \n",
              "2977  0.0  0.0  0.295912  0.0      1  \n",
              "2978  0.0  0.0  0.259197  0.0      1  \n",
              "2979  0.0  0.0  0.218751  0.0      1  \n",
              "2980  0.0  0.0  0.229689  0.0      0  \n",
              "2981  0.0  0.0  0.227259  0.0      1  \n",
              "\n",
              "[2982 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-829d2f6d-2b59-4962-8e06-7fe1b713b470\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.892458</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062522</td>\n",
              "      <td>0.044068</td>\n",
              "      <td>0.340021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132123</td>\n",
              "      <td>0.601586</td>\n",
              "      <td>0.693279</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125758</td>\n",
              "      <td>1.456933</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010732</td>\n",
              "      <td>0.445896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.274583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.175218</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190825</td>\n",
              "      <td>0.029893</td>\n",
              "      <td>0.364648</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200019</td>\n",
              "      <td>0.692391</td>\n",
              "      <td>0.829105</td>\n",
              "      <td>...</td>\n",
              "      <td>0.201026</td>\n",
              "      <td>1.800807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.615573</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.216963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.185036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149677</td>\n",
              "      <td>0.000605</td>\n",
              "      <td>0.388964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223286</td>\n",
              "      <td>0.661359</td>\n",
              "      <td>0.860664</td>\n",
              "      <td>...</td>\n",
              "      <td>0.236633</td>\n",
              "      <td>1.844458</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.601454</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.216226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.781864</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.371366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.188209</td>\n",
              "      <td>0.534919</td>\n",
              "      <td>0.746612</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214941</td>\n",
              "      <td>1.454348</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039566</td>\n",
              "      <td>0.374554</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.235217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.894115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100781</td>\n",
              "      <td>0.045623</td>\n",
              "      <td>0.313692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118110</td>\n",
              "      <td>0.606111</td>\n",
              "      <td>0.661935</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072218</td>\n",
              "      <td>1.421055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007169</td>\n",
              "      <td>0.444806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.309689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2977</th>\n",
              "      <td>1.075108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.269159</td>\n",
              "      <td>0.109561</td>\n",
              "      <td>0.265193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063702</td>\n",
              "      <td>0.706344</td>\n",
              "      <td>0.710535</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142675</td>\n",
              "      <td>1.601235</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032162</td>\n",
              "      <td>0.602430</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2978</th>\n",
              "      <td>0.851854</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.362215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.169393</td>\n",
              "      <td>0.513054</td>\n",
              "      <td>0.748830</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183976</td>\n",
              "      <td>1.462657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018008</td>\n",
              "      <td>0.375786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.259197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2979</th>\n",
              "      <td>1.126832</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.101847</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.364256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232359</td>\n",
              "      <td>0.640165</td>\n",
              "      <td>0.856988</td>\n",
              "      <td>...</td>\n",
              "      <td>0.272106</td>\n",
              "      <td>1.817077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.218751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2980</th>\n",
              "      <td>1.104989</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.373690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.234248</td>\n",
              "      <td>0.616639</td>\n",
              "      <td>0.866215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.249024</td>\n",
              "      <td>1.799792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.582558</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.229689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2981</th>\n",
              "      <td>1.038402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.387717</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233383</td>\n",
              "      <td>0.577342</td>\n",
              "      <td>0.853386</td>\n",
              "      <td>...</td>\n",
              "      <td>0.268971</td>\n",
              "      <td>1.740742</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.518036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227259</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2982 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-829d2f6d-2b59-4962-8e06-7fe1b713b470')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-829d2f6d-2b59-4962-8e06-7fe1b713b470 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-829d2f6d-2b59-4962-8e06-7fe1b713b470');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=node_emb.drop(['Class'],axis=1)\n",
        "Y=node_emb['Class']"
      ],
      "metadata": {
        "id": "r8wO9PWSAomL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score,f1_score\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "mqxQzX9FA0td"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "models = LinearSVC()\n",
        "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "y_pred = []\n",
        "y_exp = []\n",
        "\n",
        "for train_index, test_index in folds.split(X, Y):\n",
        "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    models.fit(x_train, y_train)\n",
        "    # store result from classification\n",
        "    y_pred.extend(models.predict(x_test))\n",
        "    # store expected result for this specific fold\n",
        "    y_exp.extend(y_test)\n",
        "\n",
        "print(\"Accuracy: \",  accuracy_score(y_exp, y_pred))\n",
        "print(classification_report(y_exp, y_pred))\n",
        "print(\"Confusion matrix: \", confusion_matrix(y_exp, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSup6r_MA0vK",
        "outputId": "2bd0cf92-83a2-47d4-a2c8-8584e066b389"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.57981220657277\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1253\n",
            "           1       0.58      1.00      0.73      1729\n",
            "\n",
            "    accuracy                           0.58      2982\n",
            "   macro avg       0.29      0.50      0.37      2982\n",
            "weighted avg       0.34      0.58      0.43      2982\n",
            "\n",
            "Confusion matrix:  [[   0 1253]\n",
            " [   0 1729]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(max_iter=10000) \n",
        "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "y_pred = []\n",
        "y_exp = []\n",
        "\n",
        "for train_index, test_index in folds.split(X, Y):\n",
        "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    lr.fit(x_train, y_train)\n",
        "    # store result from classification\n",
        "    y_pred.extend(lr.predict(x_test))\n",
        "    # store expected result for this specific fold\n",
        "    y_exp.extend(y_test)\n",
        "\n",
        "print(\"Accuracy: \",  accuracy_score(y_exp, y_pred))\n",
        "print(classification_report(y_exp, y_pred))\n",
        "print(\"Confusion matrix: \", confusion_matrix(y_exp, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JmLnogUA0yf",
        "outputId": "2f9ad5cf-a181-4340-fbef-1bd8d7add9cd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.57981220657277\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1253\n",
            "           1       0.58      1.00      0.73      1729\n",
            "\n",
            "    accuracy                           0.58      2982\n",
            "   macro avg       0.29      0.50      0.37      2982\n",
            "weighted avg       0.34      0.58      0.43      2982\n",
            "\n",
            "Confusion matrix:  [[   0 1253]\n",
            " [   0 1729]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "rf = RandomForestClassifier(n_estimators=300)\n",
        "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "y_pred = []\n",
        "y_exp = []\n",
        "\n",
        "for train_index, test_index in folds.split(X, Y):\n",
        "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    rf.fit(x_train, y_train)\n",
        "    # store result from classification\n",
        "    y_pred.extend(rf.predict(x_test))\n",
        "    # store expected result for this specific fold\n",
        "    y_exp.extend(y_test)\n",
        "\n",
        "print(\"Accuracy: \",  accuracy_score(y_exp, y_pred))\n",
        "print(classification_report(y_exp, y_pred))\n",
        "print(\"Confusion matrix: \", confusion_matrix(y_exp, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltoNHdaPA01l",
        "outputId": "f3d01365-d6cd-4c9f-e419-d6d31aadd5a8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5274983232729712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.32      0.36      1253\n",
            "           1       0.58      0.68      0.62      1729\n",
            "\n",
            "    accuracy                           0.53      2982\n",
            "   macro avg       0.50      0.50      0.49      2982\n",
            "weighted avg       0.51      0.53      0.51      2982\n",
            "\n",
            "Confusion matrix:  [[ 402  851]\n",
            " [ 558 1171]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=300)\n",
        "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "y_pred = []\n",
        "y_exp = []\n",
        "\n",
        "for train_index, test_index in folds.split(X, Y):\n",
        "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    gbc.fit(x_train, y_train)\n",
        "    # store result from classification\n",
        "    y_pred.extend(gbc.predict(x_test))\n",
        "    # store expected result for this specific fold\n",
        "    y_exp.extend(y_test)\n",
        "\n",
        "print(\"Accuracy: \",  accuracy_score(y_exp, y_pred))\n",
        "print(classification_report(y_exp, y_pred))\n",
        "print(\"Confusion matrix: \", confusion_matrix(y_exp, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MiwjMT7A06L",
        "outputId": "7c9a26a9-9d49-4eec-ec46-3fb410eb131e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.528504359490275\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.28      0.33      1253\n",
            "           1       0.58      0.71      0.63      1729\n",
            "\n",
            "    accuracy                           0.53      2982\n",
            "   macro avg       0.49      0.49      0.48      2982\n",
            "weighted avg       0.51      0.53      0.51      2982\n",
            "\n",
            "Confusion matrix:  [[ 354  899]\n",
            " [ 507 1222]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgbc = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, \n",
        "              gamma=0,  importance_type='gain',\n",
        "              interaction_constraints='', learning_rate=0.300000012,\n",
        "              max_delta_step=0, max_depth=6, min_child_weight=1, \n",
        "             n_estimators=200, n_jobs=16,\n",
        "              num_parallel_tree=1, random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, subsample=1,\n",
        "              tree_method='exact', use_label_encoder=False\n",
        "              )\n",
        "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "y_pred = []\n",
        "y_exp = []\n",
        "\n",
        "for train_index, test_index in folds.split(X, Y):\n",
        "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    xgbc.fit(x_train, y_train)\n",
        "    # store result from classification\n",
        "    y_pred.extend(xgbc.predict(x_test))\n",
        "    # store expected result for this specific fold\n",
        "    y_exp.extend(y_test)\n",
        "\n",
        "print(\"Accuracy: \",  accuracy_score(y_exp, y_pred))\n",
        "print(classification_report(y_exp, y_pred))\n",
        "print(\"Confusion matrix: \", confusion_matrix(y_exp, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJz6qiuQA076",
        "outputId": "df4e3e68-c626-4981-ad0e-4b0ad2b2d031"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5311871227364185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.29      0.34      1253\n",
            "           1       0.58      0.70      0.64      1729\n",
            "\n",
            "    accuracy                           0.53      2982\n",
            "   macro avg       0.50      0.50      0.49      2982\n",
            "weighted avg       0.51      0.53      0.51      2982\n",
            "\n",
            "Confusion matrix:  [[ 366  887]\n",
            " [ 511 1218]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb = lgb.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
        "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "               n_estimators=400, n_jobs=-1, num_leaves=31, objective=None,\n",
        "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
        "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
        "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "y_pred = []\n",
        "y_exp = []\n",
        "\n",
        "for train_index, test_index in folds.split(X, Y):\n",
        "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    lgb.fit(x_train, y_train)\n",
        "    # store result from classification\n",
        "    y_pred.extend(lgb.predict(x_test))\n",
        "    # store expected result for this specific fold\n",
        "    y_exp.extend(y_test)\n",
        "\n",
        "print(\"Accuracy: \",  accuracy_score(y_exp, y_pred))\n",
        "print(classification_report(y_exp, y_pred))\n",
        "print(\"Confusion matrix: \", confusion_matrix(y_exp, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0uI-sW0A0_y",
        "outputId": "85dd365c-92c2-43b8-cbf3-43fb26c29aa3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5171026156941649\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.36      0.38      1253\n",
            "           1       0.58      0.63      0.60      1729\n",
            "\n",
            "    accuracy                           0.52      2982\n",
            "   macro avg       0.49      0.50      0.49      2982\n",
            "weighted avg       0.51      0.52      0.51      2982\n",
            "\n",
            "Confusion matrix:  [[ 449  804]\n",
            " [ 636 1093]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7, stratify=Y)"
      ],
      "metadata": {
        "id": "ECWU6-oZA1Cw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "pa=PassiveAggressiveClassifier(max_iter=1000, random_state=7, tol=1e-3)\n",
        "pa.fit(x_train, y_train)\n",
        "y_pred=pa.predict(x_test)\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('accuracy_score: ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKyRBKolAonx",
        "outputId": "3947943b-e82f-4fc7-e900-18437b2c39e7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[251   0]\n",
            " [346   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      1.00      0.59       251\n",
            "           1       0.00      0.00      0.00       346\n",
            "\n",
            "    accuracy                           0.42       597\n",
            "   macro avg       0.21      0.50      0.30       597\n",
            "weighted avg       0.18      0.42      0.25       597\n",
            "\n",
            "accuracy_score:  0.4204355108877722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "lsvm = LinearSVC()\n",
        "lsvm.fit(x_train, y_train)\n",
        "y_pred=lsvm.predict(x_test)\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('accuracy_score: ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MQ9Ri_dAorv",
        "outputId": "857184e0-2361-4668-dbc6-01fa82a07b62"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0 251]\n",
            " [  0 346]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       251\n",
            "           1       0.58      1.00      0.73       346\n",
            "\n",
            "    accuracy                           0.58       597\n",
            "   macro avg       0.29      0.50      0.37       597\n",
            "weighted avg       0.34      0.58      0.43       597\n",
            "\n",
            "accuracy_score:  0.5795644891122278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=300)\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred=rf.predict(x_test)\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('accuracy_score: ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4IuM01gBVcB",
        "outputId": "a74dc576-7cd7-4b6c-c233-6c970387d803"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 84 167]\n",
            " [119 227]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.33      0.37       251\n",
            "           1       0.58      0.66      0.61       346\n",
            "\n",
            "    accuracy                           0.52       597\n",
            "   macro avg       0.49      0.50      0.49       597\n",
            "weighted avg       0.51      0.52      0.51       597\n",
            "\n",
            "accuracy_score:  0.5209380234505863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgbc = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, \n",
        "              gamma=0,  importance_type='gain',\n",
        "              interaction_constraints='', learning_rate=0.300000012,\n",
        "              max_delta_step=0, max_depth=6, min_child_weight=1, \n",
        "             n_estimators=200, n_jobs=16,\n",
        "              num_parallel_tree=1, random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, subsample=1,\n",
        "              tree_method='exact', use_label_encoder=False\n",
        "              )\n",
        "xgbc.fit(x_train, y_train)\n",
        "y_pred=xgbc.predict(x_test)\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('accuracy_score: ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrqnvjgjBVde",
        "outputId": "998dec06-2bfe-445b-919c-b6d91fd1c769"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 84 167]\n",
            " [114 232]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.33      0.37       251\n",
            "           1       0.58      0.67      0.62       346\n",
            "\n",
            "    accuracy                           0.53       597\n",
            "   macro avg       0.50      0.50      0.50       597\n",
            "weighted avg       0.52      0.53      0.52       597\n",
            "\n",
            "accuracy_score:  0.5293132328308208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log = LogisticRegression(max_iter=10000) \n",
        "log.fit(x_train, y_train)\n",
        "y_pred=log.predict(x_test)\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('accuracy_score: ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkRhrzy-BVhh",
        "outputId": "5d5b2039-9135-4c01-ad71-adb0d332ab89"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0 251]\n",
            " [  0 346]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       251\n",
            "           1       0.58      1.00      0.73       346\n",
            "\n",
            "    accuracy                           0.58       597\n",
            "   macro avg       0.29      0.50      0.37       597\n",
            "weighted avg       0.34      0.58      0.43       597\n",
            "\n",
            "accuracy_score:  0.5795644891122278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}